{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Threats with Text Classification\n",
    "This notebook demonstarate classifying threats with the natural language processing techniques.\n",
    "\n",
    "\n",
    "## Getting started\n",
    "\n",
    "First, import the packages we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set global plotting options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(\n",
    "    context='notebook',\n",
    "    font_scale=1.4,\n",
    "    color_codes=False,\n",
    "    palette=sns.color_palette('tab10', 10),\n",
    "    \n",
    "    style='whitegrid',\n",
    "    rc={\n",
    "        'figure.figsize': (12, 7.5)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ETL\n",
    "\n",
    "#### Load the updated NC4 data and removes the blank lines between rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc4 = pd.read_csv('../../datasets/NC4/NC4_update_2019-09-04.csv', encoding='latin', skip_blank_lines=True)\n",
    "nc4_mod = nc4[['gist', 'type']]\n",
    "nc4_mod.dropna(how=\"all\", inplace=True)\n",
    "nc4_mod.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the mapping excel for NC4 database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.read_excel('../../datasets/NC4/NC4_CCS_Mapping.xlsx')\n",
    "mapping.rename(columns={'NC4 Category': 'type'}, inplace=True)\n",
    "#mapping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the NC4 and mapping database on the basis of type in NC4 database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threats = pd.merge(nc4_mod, mapping, on=['type'], how='inner')\n",
    "threats.rename(columns={'gist': 'Text','Proposed CCS Category':'Category','CCS Subcategory':'Subcategory'}, inplace=True)\n",
    "threats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threats.to_csv('combined_mapping_threats.csv', sep='\\t', encoding='utf-8')\n",
    "threats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the merged database into Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = threats.sample(frac=0.8, random_state=99)\n",
    "test = threats.loc[~threats.index.isin(train.index), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Modeling\n",
    "#### Creating vocabulary from training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_docs = set(chain(*[i.split() for i in train['Text'].unique()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying model using Bayes theorem on training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english', vocabulary=vocab_docs)), \n",
    "                     ('tfidf', TfidfTransformer()), \n",
    "                     ('clf', MultinomialNB(fit_prior=False)),])\n",
    "text_clf = text_clf.fit(train.Text, train.Subcategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(test.Text)\n",
    "print(\"Accuracy is %s \" % (np.mean(predicted == test.Subcategory)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimising parameters using grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],'tfidf__use_idf': (True, False),'clf__alpha': (1e-2, 1e-3),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(train.Text, train.Subcategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = gs_clf.predict(test.Text)\n",
    "print(\"Modified accuracy is %s \" % (np.mean(predicted == test.Subcategory)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf.best_score_\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing false predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Predicted Subcategory'] = predicted\n",
    "nc4 = test[predicted != test.Subcategory]\n",
    "#nc4.to_csv('nc4.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame({'Test' : test.groupby( [ \"Subcategory\"] ).size()}).reset_index()\n",
    "false_data = pd.DataFrame({'False' : nc4.groupby( [ \"Subcategory\"] ).size()}).reset_index()\n",
    "false_threats = pd.merge(test_data, false_data, on=['Subcategory'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = false_threats.set_index('Subcategory').plot.bar(rot=90, subplots=True, figsize=(15,10), fontsize=12)\n",
    "axes[0].legend(loc=2)  # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Correct_predicted_subcategories = false_threats.Subcategory[false_threats['False'].isnull()]\n",
    "Correct_predicted_subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, label in zip(test.Text, test.Subcategory):\n",
    "    result = gs_clf.predict([item])\n",
    "    if result != label:\n",
    "        print(\"Text is %s predicted label is %s, but true label is %s\" % (item, result, label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "user_classification",
   "language": "python",
   "name": "user_classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
